<!-- #######  YAY, I AM THE SOURCE EDITOR! #########-->
<h1>Yapay Zeka &Ouml;ğrenme Teknikleri - Giriş</h1>
<p>&nbsp;</p>
<h2>Supervised Learning</h2>
<p>Denetimli &Ouml;ğrenme olarak ta dilimize &ccedil;evrilebilir. Se&ccedil;eceğimiz &ouml;ğrenme algoritmamıza modelleme yapabileceği yeterlilikte verinin ve bu veriden ulaşılmaya &ccedil;alışılan sonucun verilmesi gerekir. Algoritmamız eldeki veriyi ve bu verinin sonucunu kullanarak bir model geliştirir. Geliştirilen bu modelin ge&ccedil;erliliğini ve hata oranlarını bilebilmek i&ccedil;in elimizdeki veri ve sonu&ccedil;ları ile sınarız.</p>
<p>Eldeki hazır veri seti kullanılarak geliştirilmiş ve sonrasında test verisi ile ge&ccedil;erliliği sınanmış modelimizin yeni gelecek veriden doğru tahmini sonu&ccedil; &ccedil;ıkarması bazı kriterlere bağlıdır. Doğru modelleme yapılmamışsa &ccedil;ıkacak sonu&ccedil;lar da ger&ccedil;ek durumdan uzak olacaktır. Dikkat edilmesi gereken kriterler &ouml;ğrenme algoritması se&ccedil;imi, verinin ger&ccedil;ek durumu ne kadar yansıttığı, test verisinin ne kadar doğru se&ccedil;ildiği ve hazırlandığı(bu konu &ccedil;ok &ouml;nemli ve uzun bir konudur) gibi.</p>
<p>&nbsp;</p>
<h3>Regression</h3>
<p>Sayısal giriş değerleri ile sayısal ve s&uuml;reklilik i&ccedil;eren bir &ccedil;ıkış değeri &ouml;ng&ouml;rmemiz gerektiğinde kullanılır. Modeldeki hata hesaplanmasında RMSE(Root Mean Squared Error) ve MAE(Mean Absolute Error) gibi hata hesaplama y&ouml;ntemleri kullanılır. Hata sonu&ccedil;larının birim olarak değil de relatif olarak alınması i&ccedil;in de RAE(Relative Absolute Error) ve RSE(Relative Squared Error) kullanılır.</p>
<p>Hata sonucu ne kadar d&uuml;ş&uuml;kse model o kadar başarılı olmuş demektir.</p>
<p>&nbsp;</p>
<h3>Classification</h3>
<p>Eldeki verinin sınıflandırılması veya kategorize edilmesi amacıyla kullanılır. Sık kullanılan Classification algoritmaları:<br /><br /><br /></p>
<ul>
    <li>Logistic Regression</li>
    <li>Desicion Trees / Classification Trees</li>
    <li>AdaBoost</li>
    <li>SVM(Support Vector Machines)</li>
    <li>Random Forests</li>
    <li>Neural Networks</li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&Ouml;rneğin elimizdeki verinin bir kısmını A etiketiyle diğerini B etiketiyle etiketlemiş olalım. Sınıflandırma algoritması bu verileri alır, &ccedil;alışır ve bunlardan bir model oluşturur. Oluşturulan model A ve B etiketlerinin nasıl ayrılacağını &ouml;ng&ouml;ren bir modeldir. A ve B etiketli verileri birbirinden ayıracak bir yol bulur ve bu yola decision boundary yani karar sınırı denir. Sınırın bir tarafı A etiketli veri diğer tarafı B etiketli veri olacak şekilde model &uuml;retilir. Sonrasında modelimize hen&uuml;z etiketlenmemiş ve hangi etikete ait olduğunu tahmin etmesini istediğimiz veriyi g&ouml;nderdiğimizde bunun A veya B etiketinin hangisine uyduğunun tahmini yapar ve etiketler.&nbsp;</p>
<p><br /><br />Binary classification algoritmasını ele alırsak, bu model ile eldeki veriler 1 ya da 0 olarak sınıflandırır ve bu iki durumdan hangisine uyduğunu belirleyebiliriz. 1 ya da 0 olma kararı bir eşik(threshold) yardımıyla alınır. Eşik değerinden d&uuml;ş&uuml;k olan veriler 0, eşik değerinden b&uuml;y&uuml;kler ise 1 olarak sınıflandırılır.</p>
<p>Supervised learning tekniğinde modelin &ouml;ng&ouml;r&uuml;leri eldeki verilerle test edilir ve modelin ge&ccedil;erliliği ve performansı sınanmış olur. Binary Classification modelinin tahminleri test verisi ile kıyaslandığında:</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>Model 1 olarak tahmin etmiş ve test verisi 1 ise : Doğru Pozitif (True Positive)(TP)</p>
<p>Model 0 olarak tahmin etmiş ve test verisi 0 ise : Doğru Negatif (True Negative)(TN)</p>
<p>Model 1 olarak tahmin etmiş ve test verisi 0 ise : Yanlış Pozitif (False Positive)(FP)</p>
<p>Model 0 olarak tahmin etmiş ve test verisi 1 ise : Yanlış Negatif (False Negative)(FN)</p>
<p>&nbsp;</p>
<p>Elde edilen bu TP,TN,FP,FN sayıları ile Confusion Matrix ismi verilen bir matriks oluşturulur ve sınıflandırma modelimizin performansının hesaplanmasında kullanılacaktır. Confusion Matrix veya Contingency Table da denilmektedir, amacı olasılıkların bir tabloda g&ouml;sterilmesidir.</p>
<p>&nbsp;</p>
<p><u>&Ouml;rnek Confusion Matrix:</u></p>
<p><img src="https://1.bp.blogspot.com/-UYkYLsH5xxw/WdIna1UNUcI/AAAAAAAAAXc/eyNxA_xbmgMHeNYAlCmNNmclAcZhFGM6gCK4BGAYYCw/s1600/confusionmatrix.jpg" alt="" width="328" height="231" /></p>
<p>&nbsp;</p>
<p>Confusion matrix kullanılarak hesaplanan performans &ouml;l&ccedil;&uuml;mleri şunlardır:</p>
<p>&nbsp;</p>
<p><strong>Accuracy</strong>&nbsp;: Doğruluk. İsabetli tahmin edilen sınıflandırmaların, toplam sınıflandırılma sayısına b&ouml;l&uuml;m&uuml;.</p>
<p>&nbsp;</p>
<p>Accuracy = (TP + TN) / ( TP + FP + TN + FN)</p>
<p>&nbsp;</p>
<p><strong>Presicion</strong>&nbsp;: Hassasiyet. Sınıflandırıcıdan olumlu bir tahmin alındığında, bunun ger&ccedil;ekte ne kadar doğru olduğunu belirlemede kullanılır. Bu da doğru tahmin edilen pozitif &ouml;ng&ouml;r&uuml;ler sayısı ile doğru veya yanlış toplam tahmin edilen pozitif &ouml;ng&ouml;r&uuml;lerin sayısına b&ouml;l&uuml;n&uuml;r.</p>
<p>&nbsp;</p>
<p>Presicion = TP / (TP + FP)</p>
<p>&nbsp;</p>
<p><strong>Recall</strong>&nbsp;: &Ccedil;ağırma. Diğer adıyla Duyarlılık veya TPR(True Positive Rate)(Ger&ccedil;ek Olumlu Oran). Sınıflandırıcının yaptığı olumlu tahminlerin hangi kısmı kesin olarak doğru bu durumu bulmak i&ccedil;in kullanılır. Bir başka deyişle, olumlu tahminlerin sayısının, test verilerindeki pozitif sınıflandırılan değer sayısına b&ouml;l&uuml;nmesidir.</p>
<p>&nbsp;</p>
<p>Recall = TP / (TP + FN)</p>
<p>&nbsp;</p>
<p>Recall daha &ouml;nce de belirttiğim gibi True Positive Rate ismiyle de ge&ccedil;er, bunun yanında benzer bir oranlama hesabı daha vardır o da False Positive Rate. FPR ise olumsuz tahminlerin oran hesaplanmasında kullanılır. TPR ve FPR ikisi ROC(Receiver Operating Characteristic) eğrisi denilen bir eğirinin &ccedil;izilmesinde kullanılır.TPR ve FPR form&uuml;lleri:</p>
<p>&nbsp;</p>
<p>TPR = TP / (TP + FN)</p>
<p>FPR&nbsp; = FP / (FP + TN)</p>
<p>&nbsp;</p>
<p>&Ouml;rnek ROC Eğrisi:</p>
<h1 style="color: #5e9ca0;"><img src="https://1.bp.blogspot.com/-9wWWogTvjyQ/WdInvOLgCuI/AAAAAAAAAXk/ofFmNikdQ6woQkweSZPj8BueAIPAzjWPgCK4BGAYYCw/s320/ROCEgrisi.jpg" width="320" height="188" border="0" /></h1>
<p>&nbsp;</p>
<p>ROC eğrisinin altında kalan alana ise AUC(Area Under The ROC) denir. Eğri altındaki alan veya AUC, modelin ne kadar iyi &ouml;ng&ouml;receğini g&ouml;steren bir g&ouml;stergedir. Genellikle, AUC alanı ne kadar geniş ise o kadar iyidir. Grafiğin sol &uuml;st k&ouml;şesine m&uuml;mk&uuml;n olduğunca yakın olunmak istenir.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2>Unsupervised Learning</h2>
<p>&nbsp;</p>
<p>Supervised Learning tekniğindeki gibi modelimizi geliştirmek ve eğitmek i&ccedil;in elimizdeki veri sonu&ccedil;lar i&ccedil;ermeyebilir, etiketlenmemiş veya kategorize edilmemiş olabilir. Yani sadece veri k&uuml;mesine sahip olabiliriz ve bu veriler herhangi bir sonu&ccedil;la ilişkili olmayabilir. Bu durumlarda veri i&ccedil;indeki benzerlikleri keşfedip gruplamak i&ccedil;in bir takım algoritmalar kullanılır. Bunlar verideki benzerlikleri g&ouml;zlemleyerek veriyi k&uuml;melere ayırır ve onları gruplar. Amaca ve veriye g&ouml;re farklı algoritmalar (K-Means , DBSCAN, Gaussian Mixture Model, ..) kullanılmaktadır.</p>
<p>&nbsp;</p>
<h3>Clustering</h3>
<p>K&uuml;meleme, bir veri i&ccedil;indeki benzerlikleri gruplamak i&ccedil;in kullanılan bir tekniktir. K&uuml;meleme işlemini yapan algoritmalardan en pop&uuml;ler olanı K-Means clustering algoritmasıdır.</p>
<p>&nbsp;</p>
<p><strong>K-Means Algoritması</strong>&nbsp;:</p>
<p>İteratif bir algoritmadır, yani ideal sonuca ulaşana kadar &ccedil;alışmaya(k&uuml;meleme işlemine) devam eder. Elimizdeki veri uygun &ouml;zelliklere sahip ise bu veriden istenen sayıda k&uuml;meleme &ccedil;ıkarmakta kullanılır. Oluşturulacak k&uuml;me sayısı K ile ifade edilir. K k&uuml;melerinin merkezinde Centroid ismi verilen k&uuml;me merkez noktası bulunur.</p>
<p>Algoritma &ouml;nce rastgele centroid atar ve devamında bu centroid&rsquo;e yakın olan noktaları k&uuml;me i&ccedil;ine alır. K&uuml;me i&ccedil;inde kalan noktaların k&uuml;me merkezine ortalama uzaklığı ve k&uuml;me merkezinin diğer k&uuml;me merkezlerine olan ortalama uzaklığı gibi hesaplamalar yapılıp iteratif olarak k&uuml;me merkezi değiştirilir. Yeni atanan k&uuml;me merkezine en yakın noktalardan tekrar bir k&uuml;me oluşturulur ve işlem bu şekilde mevcut k&uuml;me merkezi değişmeyene dek (ideal konuma ulaşana kadar) kaydırılır.</p>
<p>&nbsp;</p>
<p><strong>Principal Component Analysis(PCA) :</strong></p>
<p>PCA, ismine bakıldığında ve internetteki kaynaklar incelendiğinde mantığının zor gibi g&ouml;z&uuml;kmesine rağmen &ouml;yle değil. Hem anlaşılabilir hem de bir c&uuml;mleye sığdırarak anlatmaya &ccedil;alışacağım.</p>
<p>&nbsp;</p>
<p>PCA temel olarak elimizdeki verinin boyutlarını indirgemeye yarar, bu şekilde k&uuml;meleme işlemimizi daha az boyut kullanarak ve karmaşası azalmış bir şekilde &ccedil;&ouml;zmemize yardımcı olur.</p>
<p>&nbsp;</p>
<p>Yukarıdaki c&uuml;mle yeterli olmadıysa pek &ccedil;ok sitedeki karmaşık anlatımla verildiğinde ş&ouml;yle anlatılabilir. Elimizde N boyutlu veri olsun, &ouml;ncelikle bunun NxN boyutlu kovaryans Matrisi bulunur, matrisin N adet eigen value değerleri bulunur, bunlardan eigen vector&rsquo;ler hesaplanır. Verimiz bu eigen vector&rsquo;lere iz d&uuml;ş&uuml;r&uuml;lerek boyut indirgenmiş olur.</p>
<p>&nbsp;</p>
<p>Tekrar anlaşılabilir versiyona ge&ccedil;ildiğinde iki &ouml;rnekle bitireyim. &Ouml;rneğin elimizde iki boyutlu verimiz olsun, PCA ile bu verileri bir boyuttaki vekt&ouml;re indirgeyebiliriz. Ya da &uuml;&ccedil; boyutlu verimiz var diyelim. Boyutları x1,x2,x3 olsun. Bu veriyi 2 boyutlu bir y&uuml;zeye indirgeyebiliriz(elimizde iki vekt&ouml;r olur). Temel olarak PCA ile elimizdeki verinin bir boyut aşağıya indirgemesini yapabiliriz.</p>
<p>&nbsp;</p>
<p>&nbsp;</p>